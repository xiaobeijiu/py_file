{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bf223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31965ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. 准备无监督数据 ==========\n",
    "# 读取CSV文件\n",
    "data = pd.read_csv('your_data.csv')\n",
    "X = data.values  # 如果整个文件都是数值特征\n",
    "# 或者选择特定列: X = data[['col1', 'col2', 'col3']].values\n",
    "\n",
    "# 数据预处理（根据需要）\n",
    "# 1. 处理缺失值\n",
    "# X = pd.DataFrame(X).fillna(method='mean').values\n",
    "# 2. 标准化（可选）\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(f'数据形状: {n_samples} 样本, {n_features} 特征')\n",
    "\n",
    "# ========== 2. 构造伪标签数据（用于无监督随机森林） ==========\n",
    "# 随机打乱数据并构造伪造样本\n",
    "X_fake = np.random.uniform(low=X.min(axis=0), high=X.max(axis=0), size=X.shape)\n",
    "\n",
    "# 合并真实和伪造数据\n",
    "X_combined = np.vstack((X, X_fake))\n",
    "y_combined = np.hstack((np.ones(n_samples), np.zeros(n_samples)))  # 1: 真实，0: 伪造\n",
    "\n",
    "# ========== 3. 训练随机森林分类器 ==========\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "rf.fit(X_combined, y_combined)\n",
    "\n",
    "# ========== 4. 提取 Gini 不纯度减少量 ==========\n",
    "feature_importance_raw = rf.feature_importances_  # 即 MDG\n",
    "\n",
    "# ========== 5. 标准化 MDG 值到 [0,1] 区间 ==========\n",
    "scaler = MinMaxScaler()\n",
    "feature_importance_scaled = scaler.fit_transform(feature_importance_raw.reshape(-1, 1)).flatten()\n",
    "\n",
    "# ========== 6. 输出结果 ==========\n",
    "# 生成特征名称（如果数据没有列名）\n",
    "# 如果使用pandas读取的数据有列名，可以用: feature_names = data.columns.tolist()\n",
    "try:\n",
    "    feature_names = load_iris().feature_names  # 示例数据的特征名\n",
    "except:\n",
    "    feature_names = [f'Feature_{i+1}' for i in range(n_features)]  # 自动生成特征名\n",
    "\n",
    "# 创建结果DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'MDG': feature_importance_raw,\n",
    "    'MDG_scaled': feature_importance_scaled,\n",
    "    'Rank': range(1, len(feature_importance_scaled) + 1)\n",
    "}).sort_values(by='MDG_scaled', ascending=False)\n",
    "\n",
    "# 重新设置排名\n",
    "importance_df['Rank'] = range(1, len(importance_df) + 1)\n",
    "\n",
    "print('特征重要性排序结果:')\n",
    "print(importance_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
